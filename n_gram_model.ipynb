{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/nikil/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "import operator\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autocorrect(object):\n",
    "    def __init__(self,size_of_ngram=3,size_of_variance=1):\n",
    "        \"\"\"\n",
    "        implementation of autocorrect using trigrams\n",
    "        \"\"\"\n",
    "        self.size_of_ngram=size_of_ngram\n",
    "        self.size_of_variance=size_of_variance\n",
    "        self.words_bag=set(words.words()) #word corpus in nltk\n",
    "        self.ngram_words_bag=collections.defaultdict(set)\n",
    "        #create dict of trigrams \n",
    "        for word in self.words_bag:\n",
    "            for ngram in self.ngrams_of_word(word):\n",
    "                self.ngram_words_bag[ngram].add(word)            \n",
    "    \n",
    "    def ngrams_of_word(self,word):\n",
    "        \"for a given word return set of trigrams from that word\"\n",
    "        ngrams=set()\n",
    "        for i in range(0,len(word)-self.size_of_ngram+1):\n",
    "            ngrams.add(word[i:i+self.size_of_ngram])\n",
    "        return ngrams    \n",
    "    \n",
    "    def checker(self,word):\n",
    "        \"returns true if the word is in words_bag\"\n",
    "        if word in self.words_bag:\n",
    "            return True\n",
    "    \n",
    "    def suggestions(self,given_word,searches=4):\n",
    "        word_ranking=collections.defaultdict(int)\n",
    "        suggested_words=set()\n",
    "        for ngram in self.ngrams_of_word(given_word):\n",
    "            words=self.ngram_words_bag[ngram]\n",
    "            for word in words:\n",
    "                if len(word) >= len(given_word) - self.size_of_variance and len(word) <= len(given_word) + self.size_of_variance:\n",
    "                    word_ranking[word] += 1\n",
    "        ranked_word_pairs = sorted(word_ranking.items(), key=operator.itemgetter(1))\n",
    "        return [word_pair[0] for word_pair in ranked_word_pairs[0:searches]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER A WORD: lioa\n",
      "['Eliot', 'olio', 'lion', 'julio']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    autocorrect=Autocorrect()\n",
    "    word=input(\"ENTER A WORD: \").lower()\n",
    "    if autocorrect.checker(word):\n",
    "        print(\"No suggestions required\")\n",
    "    else:\n",
    "        suggested_words = autocorrect.suggestions(word)\n",
    "        print (suggested_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
